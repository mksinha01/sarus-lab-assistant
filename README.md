# Sarus - AI Lab Assistant Robot (Jarvis + Sarus Integration)

ğŸ”¬ **Sarus** is an advanced autonomous AI lab assistant that merges the capabilities of Inventor Usman's Mark 1 (Jarvis) with Sarus robotic platform. Built on Raspberry Pi 4, this intelligent robot combines voice interaction, environmental monitoring, safety systems, and autonomous navigation to create a comprehensive lab assistant that can speak, reason, monitor conditions, detect hazards, and assist researchers with human-like proficiency.

## ğŸŒŸ Key Features

### ğŸ¤ Voice Interaction & Control
- **Wake Word Detection**: Activated with "Hey Sarus" using Porcupine/VOSK
- **Offline Speech Processing**: Local STT (VOSK/Whisper) + LLaMA LLM + TTS pipeline
- **Intelligent Command Processing**: Natural language understanding for movement and queries
- **Technical Q&A**: Answers math calculations, definitions, and project-related questions
- **Web-Enhanced Knowledge**: Optional API calls for real-time information retrieval

### ï¿½ï¸ Safety & Environmental Monitoring
- **Continuous Environmental Monitoring**: DHT22 sensor for temperature and humidity tracking
- **Gas Leak Detection**: MQ-series gas sensors with automatic alert system
- **Safety Protocols**: Autonomous hazard detection with vocal warnings and emergency stops
- **Real-Time Safety Reporting**: Voice-activated environmental status queries

### ğŸ” Security & Access Control
- **Facial Recognition**: OpenCV-based user authentication system
- **Authorized User Control**: Only responds to recognized personnel
- **Intruder Detection**: Alerts and logging for unknown individuals
- **Lab Security Monitoring**: Continuous surveillance with intelligent alerts

### ğŸ‘ï¸ Computer Vision & Object Recognition
- **Lab Equipment Detection**: YOLO-based identification of multimeters, oscilloscopes, etc.
- **Object Navigation**: Voice-commanded movement to specific equipment
- **Scene Understanding**: LLaVA/BLIP image captioning for descriptive responses
- **Visual Feedback**: LED matrix displays for robot status and emotions

### ğŸ§­ Autonomous Navigation & Mobility
- **Voice-Controlled Movement**: "Move forward," "turn right," "go to the multimeter"
- **Obstacle Avoidance**: Ultrasonic sensors for collision prevention
- **Autonomous Exploration**: Goal-based movement with path learning
- **Manual Override**: Xbox controller for testing and debugging

### ï¿½ Intelligent Logging & Reporting
- **Mission Summaries**: AI-generated natural language reports after tasks
- **Environmental Data Logging**: Time-series data of temperature, humidity, gas levels
- **Activity Monitoring**: Tracks interactions, observations, and system status
- **Voice Reports**: Spoken summaries of findings and observations

## ğŸ§° Hardware Requirements

| Component | Purpose | Notes |
|-----------|---------|-------|
| **Core Processing** |
| Raspberry Pi 4 | Main CPU for AI processing | 4GB+ RAM recommended |
| MicroSD Card (64GB+) | OS and model storage | Fast Class 10 or better |
| **Audio System** |
| USB Microphone | Voice input for commands | Noise-canceling preferred |
| USB Speaker/Audio HAT | TTS voice output | Clear audio for responses |
| **Vision & Display** |
| Pi Camera/USB Webcam | Computer vision and monitoring | 1080p or higher |
| LED Matrix Display | Facial animations and status | 8x8 or 16x16 matrix |
| **Environmental Sensors** |
| DHT22 Sensor | Temperature and humidity | Â±0.5Â°C accuracy |
| MQ Gas Sensor (MQ-2/MQ-5) | Gas leak detection | For lab safety monitoring |
| ADC Module (MCP3008) | Analog sensor interface | For gas sensor readings |
| **Mobility & Control** |
| DC Motors + Wheels | Robot locomotion | Encoded motors preferred |
| Motor Driver (L298N) | Motor control interface | H-bridge for bidirectional control |
| Ultrasonic Sensors (HC-SR04) | Obstacle detection | Multiple sensors for 360Â° coverage |
| Xbox Controller | Manual override control | Wireless USB adapter |
| **Power & Structure** |
| Li-ion Battery Pack | Portable power supply | 5V/3A output minimum |
| 3D Printed Chassis | Physical robot body | Custom design for sensor mounting |
| Jumper Wires & Breadboard | Electronic connections | For prototyping and connections |

## ğŸ§  Enhanced Software Stack

| System | Technology | Purpose |
|--------|------------|---------|
| **Core OS** |
| Operating System | Raspberry Pi OS Lite | Lightweight Linux distribution |
| **AI & Language Processing** |
| Wake Word Detection | Porcupine/VOSK | "Hey Sarus" activation |
| Speech-to-Text | VOSK/Whisper | Offline voice transcription |
| Language Model (Local) | LLaMA via llama.cpp | Privacy-focused reasoning |
| Language Model (Cloud) | ChatGPT-4/Claude | Fallback for complex queries |
| Text-to-Speech | Coqui/Piper | Natural voice synthesis |
| **Computer Vision** |
| Object Detection | YOLOv5/YOLOv8 | Lab equipment recognition |
| Image Captioning | LLaVA/BLIP | Scene understanding |
| Face Recognition | OpenCV + dlib | User authentication |
| **Environmental Monitoring** |
| Sensor Interface | Adafruit CircuitPython | DHT22, MQ sensors |
| Data Logging | SQLite/InfluxDB | Time-series environmental data |
| Alert System | Custom Python | Real-time hazard detection |
| **Navigation & Control** |
| Motor Control | RPi.GPIO/gpiozero | DC motor driving |
| Path Planning | Custom algorithms | Obstacle avoidance |
| Controller Input | pygame | Xbox controller interface |
| **Safety & Security** |
| Access Control | Custom facial recognition | Authorized user verification |
| Emergency Systems | Hardware interrupts | Immediate safety responses |
| Logging & Audit | JSON/SQLite | Security event tracking |

## ğŸš€ Quick Start

### Installation

1. **Clone and setup the project**:
   ```bash
   git clone https://github.com/mksinha01/sarus-lab-assistant.git
   cd sarus-lab-assistant
   ```

2. **Install system dependencies**:
   ```bash
   sudo apt update
   sudo apt install python3-pip python3-venv git cmake build-essential
   sudo apt install portaudio19-dev python3-pyaudio
   ```

3. **Create virtual environment and install Python dependencies**:
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   pip install -r requirements.txt
   ```

4. **Configure hardware settings**:
   ```bash
   cp src/config/hardware_config.example.py src/config/hardware_config.py
   # Edit the configuration file to match your hardware setup
   ```

5. **Download AI models**:
   ```bash
   # Download VOSK model for speech recognition
   ./scripts/download_models.sh
   
   # Or manually download and place in data/models/
   ```

6. **Run initial setup and calibration**:
   ```bash
   python setup_calibration.py
   ```

7. **Start Sarus**:
   ```bash
   python main.py
   ```

### Basic Usage Examples

#### ğŸ¤ **Voice Commands**
1. **Wake up Sarus**: Say "Hey Sarus"
2. **Movement commands**:
   - "Move forward"
   - "Turn right" 
   - "Stop"
   - "Go to the multimeter"

3. **Environmental queries**:
   - "What's the lab temperature?"
   - "Check humidity levels"
   - "Any gas leaks detected?"

4. **Technical assistance**:
   - "What is 12 times 7?"
   - "Explain Ohm's law"
   - "What do you see?"

5. **Lab navigation**:
   - "Explore the room"
   - "Find the oscilloscope"
   - "Return to base"

#### ğŸ® **Manual Control**
- Use Xbox controller for direct movement during testing
- Override voice commands with manual control
- Emergency stop with controller

#### ğŸ“Š **Status Monitoring**
- Check `logs/` directory for mission reports
- View real-time sensor data in web dashboard
- Monitor system health and alerts

## ğŸ’¬ Example Interactions

### Environmental Monitoring
```
User: "Hey Sarus, what's the lab temperature and humidity?"
Sarus: "Lab temperature is 22Â°C and humidity is 45%. I detect no hazardous gases."

User: "Set up environmental monitoring for the next hour"
Sarus: "Environmental monitoring activated. I'll alert you if any values exceed safe thresholds."
```

### Safety & Security
```
User: "Sarus, patrol the lab"
Sarus: "Beginning lab patrol. I'll monitor for unauthorized personnel and safety hazards."

[Gas leak detected]
Sarus: "WARNING: Gas leak detected! Levels are above safe threshold. Evacuating area immediately!"
```

### Technical Assistance
```
User: "What's the formula for power calculation?"
Sarus: "Power equals voltage times current, P = V Ã— I. For AC circuits, you may also need to consider power factor."

User: "Calculate the resistance for a 5V supply with 2A current"
Sarus: "Using Ohm's law, R = V/I = 5V/2A = 2.5 ohms."
```

### Object Recognition & Navigation
```
User: "What equipment do you see?"
Sarus: "I can see an oscilloscope on the left bench, a multimeter on the right table, and a power supply unit near the window."

User: "Go to the multimeter"
Sarus: "Navigating to the multimeter on the right table. Avoiding obstacles... Arrived at destination."
```

## ğŸ“ Project Structure

```
sarus-lab-assistant/
â”œâ”€â”€ main.py                     # Main entry point
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ setup_calibration.py       # Initial setup and sensor calibration
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_models.sh     # Download AI models
â”‚   â”œâ”€â”€ install_dependencies.sh # System setup script
â”‚   â””â”€â”€ deploy_pi.sh          # Raspberry Pi deployment
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                  # Core robot systems
â”‚   â”‚   â”œâ”€â”€ robot.py          # Main robot controller
â”‚   â”‚   â”œâ”€â”€ state_machine.py  # Robot state management
â”‚   â”‚   â””â”€â”€ safety_manager.py # Safety protocols
â”‚   â”œâ”€â”€ ai/                    # AI and ML modules
â”‚   â”‚   â”œâ”€â”€ speech/           # STT/TTS systems
â”‚   â”‚   â”œâ”€â”€ llm/              # Language model interface
â”‚   â”‚   â”œâ”€â”€ vision/           # Computer vision
â”‚   â”‚   â””â”€â”€ voice_agent.py    # Voice conversation system
â”‚   â”œâ”€â”€ hardware/             # Hardware control
â”‚   â”‚   â”œâ”€â”€ sensors/          # Environmental sensors
â”‚   â”‚   â”œâ”€â”€ motors/           # Motor control
â”‚   â”‚   â”œâ”€â”€ camera/           # Camera interface
â”‚   â”‚   â””â”€â”€ display/          # LED matrix control
â”‚   â”œâ”€â”€ navigation/           # Movement and pathfinding
â”‚   â”‚   â”œâ”€â”€ path_planner.py   # Route planning
â”‚   â”‚   â”œâ”€â”€ obstacle_avoidance.py # Collision avoidance
â”‚   â”‚   â””â”€â”€ localization.py   # Position tracking
â”‚   â”œâ”€â”€ safety/               # Safety and security
â”‚   â”‚   â”œâ”€â”€ gas_monitor.py    # Gas leak detection
â”‚   â”‚   â”œâ”€â”€ face_recognition.py # User authentication
â”‚   â”‚   â””â”€â”€ emergency_stop.py # Emergency protocols
â”‚   â”œâ”€â”€ communication/        # Voice and network
â”‚   â”‚   â”œâ”€â”€ voice_interface.py # Voice I/O
â”‚   â”‚   â”œâ”€â”€ web_dashboard.py  # Web interface
â”‚   â”‚   â””â”€â”€ notifications.py  # Alert system
â”‚   â”œâ”€â”€ config/              # Configuration files
â”‚   â”‚   â”œâ”€â”€ settings.py      # Main configuration
â”‚   â”‚   â”œâ”€â”€ hardware_config.py # Hardware pin assignments
â”‚   â”‚   â””â”€â”€ ai_config.py     # AI model settings
â”‚   â””â”€â”€ utils/               # Utility functions
â”‚       â”œâ”€â”€ logging.py       # Enhanced logging
â”‚       â”œâ”€â”€ data_processing.py # Data analysis
â”‚       â””â”€â”€ calibration.py   # Sensor calibration
â”œâ”€â”€ data/                    # AI models and datasets
â”‚   â”œâ”€â”€ models/             # Downloaded AI models
â”‚   â”œâ”€â”€ voice_samples/      # Training audio
â”‚   â”œâ”€â”€ face_encodings/     # Authorized user faces
â”‚   â””â”€â”€ calibration/        # Sensor calibration data
â”œâ”€â”€ logs/                   # Log files and reports
â”‚   â”œâ”€â”€ mission_reports/    # Task summaries
â”‚   â”œâ”€â”€ environmental/      # Sensor data logs
â”‚   â”œâ”€â”€ security/          # Security events
â”‚   â””â”€â”€ system/            # System diagnostics
â”œâ”€â”€ web/                   # Web dashboard files
â”‚   â”œâ”€â”€ static/            # CSS, JS, images
â”‚   â”œâ”€â”€ templates/         # HTML templates
â”‚   â””â”€â”€ app.py            # Flask web application
â”œâ”€â”€ tests/                 # Unit and integration tests
â”‚   â”œâ”€â”€ unit/             # Unit tests
â”‚   â”œâ”€â”€ integration/      # Integration tests
â”‚   â””â”€â”€ hardware/         # Hardware tests
â””â”€â”€ docs/                 # Documentation
    â”œâ”€â”€ hardware_setup.md # Hardware assembly guide
    â”œâ”€â”€ software_setup.md # Software installation
    â”œâ”€â”€ api_reference.md  # API documentation
    â””â”€â”€ troubleshooting.md # Common issues and fixes
```

## ğŸ”Œ Advanced Features & Extensions

### ğŸŒ **Connectivity & Remote Access**
- **Wi-Fi Communication** â€“ Remote access via SSH or WebSocket server
- **Web Dashboard** â€“ Live video feed, logs, and control via Flask
- **Mobile App Integration** â€“ Android/iOS app for remote control
- **API Endpoints** â€“ RESTful API for external integrations

### ï¿½ **Enhanced Security**
- **Multi-Factor Authentication** â€“ Voice + face recognition
- **Encrypted Communications** â€“ Secure data transmission
- **Access Logging** â€“ Detailed audit trails
- **Intruder Deterrent** â€“ Active response to unauthorized access

### ğŸ§ª **Lab-Specific Features**
- **Equipment Interface** â€“ Direct control of lab instruments
- **QR Code Reading** â€“ Sample and equipment identification
- **Chemical Database** â€“ Safety data sheet lookup
- **Experiment Assistance** â€“ Step-by-step procedure guidance

### ğŸ¤– **AI Enhancements**
- **Continuous Learning** â€“ Adaptation to lab environment
- **Predictive Maintenance** â€“ Equipment failure prediction
- **Natural Conversations** â€“ Context-aware dialogue
- **Multi-Language Support** â€“ International lab support

### ğŸ”§ **Developer Features**
- **Plugin System** â€“ Custom Python modules for specialized tasks
- **Model Swapping** â€“ Easy AI model updates
- **Sensor Integration** â€“ Simple addition of new sensors
- **Custom Commands** â€“ User-defined voice commands

## ğŸ“„ Use Cases and Target Audience

### ğŸ”¬ **Research Laboratories**
- **Automated Experiments** â€“ Voice-controlled instrument operation and data collection
- **Safety Monitoring** â€“ Continuous environmental hazard detection and emergency response
- **Equipment Management** â€“ Intelligent equipment location and status monitoring
- **Data Logging** â€“ Comprehensive environmental and operational data recording
- **Protocol Assistance** â€“ Step-by-step experimental procedure guidance

### ğŸ« **Educational Institutions**
- **Student Interaction** â€“ Interactive learning companion for lab safety and procedures
- **Equipment Training** â€“ Voice-guided tutorials for lab equipment operation
- **Safety Education** â€“ Real-time safety monitoring and hazard education
- **Research Support** â€“ Assistance with data collection and analysis
- **Accessibility** â€“ Voice interface for students with mobility limitations

### ğŸ  **Makers & Hobbyists**
- **DIY Projects** â€“ Voice-interactive assistant for electronics and robotics projects
- **Workshop Safety** â€“ Environmental monitoring for home workshops
- **Learning Platform** â€“ Hands-on AI and robotics education
- **Privacy-First** â€“ Local processing keeps personal data secure
- **Customizable** â€“ Open-source platform for experimentation

### ğŸ‘¨â€ğŸ’» **Developers & Engineers**
- **AI Research Platform** â€“ Test bed for new AI models and algorithms
- **Robotics Development** â€“ Complete robotics stack for prototyping
- **Edge Computing** â€“ Local AI processing optimization and benchmarking
- **Sensor Integration** â€“ Platform for testing new sensor technologies
- **Open Source Contribution** â€“ Community-driven development and improvements

## ğŸ›¡ï¸ Safety & Security Protocols

### âš ï¸ **Emergency Response Systems**
- **Gas Leak Detection** â€“ Immediate vocal alerts and area evacuation protocols
- **Fire Safety** â€“ Temperature spike detection and emergency notifications
- **Chemical Spill Response** â€“ Automated hazard identification and response procedures
- **Medical Emergency** â€“ Integration with lab emergency systems
- **Hardware Failures** â€“ Fail-safe modes for critical system failures

### ğŸ” **Access Control & Security**
- **Multi-Level Authentication** â€“ Face recognition + voice verification
- **Authorized Personnel Database** â€“ Secure storage of approved user profiles
- **Activity Logging** â€“ Complete audit trail of all interactions
- **Intrusion Detection** â€“ Unauthorized access alerts and response
- **Data Encryption** â€“ Secure storage and transmission of sensitive data

### ğŸ“Š **Compliance & Monitoring**
- **Environmental Standards** â€“ Continuous monitoring against safety thresholds
- **Usage Analytics** â€“ Equipment utilization and safety metrics
- **Incident Reporting** â€“ Automated generation of safety incident reports
- **Regulatory Compliance** â€“ Support for lab safety regulations and standards
- **Quality Assurance** â€“ System reliability and performance monitoring

## ğŸš€ Implementation Roadmap

### Phase 1: Core Foundation (Weeks 1-4)
- [x] **Voice conversation system** - Implemented with Gemini AI integration
- [x] **Basic robot simulation** - PyBullet 3D environment ready
- [x] **Custom robot models** - Multiple robot types available
- [ ] **Hardware integration** - Raspberry Pi setup and sensor connections
- [ ] **Basic movement control** - Motor drivers and navigation

### Phase 2: AI & Vision (Weeks 5-8)
- [ ] **Local LLM integration** - LLaMA model deployment
- [ ] **Computer vision setup** - YOLO object detection
- [ ] **Face recognition system** - OpenCV user authentication
- [ ] **Speech processing optimization** - VOSK/Whisper integration
- [ ] **Natural language processing** - Command understanding

### Phase 3: Safety & Monitoring (Weeks 9-12)
- [ ] **Environmental sensors** - DHT22 temperature/humidity monitoring
- [ ] **Gas detection system** - MQ sensor integration and alerts
- [ ] **Safety protocols** - Emergency response procedures
- [ ] **Data logging system** - Environmental and operational data
- [ ] **Alert mechanisms** - Voice and visual warning systems

### Phase 4: Advanced Features (Weeks 13-16)
- [ ] **Web dashboard** - Remote monitoring and control interface
- [ ] **Mobile app integration** - Smartphone control capabilities
- [ ] **Advanced navigation** - SLAM and path planning
- [ ] **Lab equipment integration** - Direct instrument control
- [ ] **Machine learning optimization** - Performance improvements

### Phase 5: Testing & Deployment (Weeks 17-20)
- [ ] **Comprehensive testing** - Unit, integration, and field testing
- [ ] **Documentation completion** - User guides and API documentation
- [ ] **Performance optimization** - Speed and reliability improvements
- [ ] **Security auditing** - Penetration testing and vulnerability assessment
- [ ] **Production deployment** - Final system rollout and training

## ğŸ› ï¸ Development & Configuration

### Testing
```bash
# Run all tests
python -m pytest tests/

# Run specific test categories
python -m pytest tests/unit/          # Unit tests
python -m pytest tests/integration/   # Integration tests
python -m pytest tests/hardware/      # Hardware tests

# Test voice system
python tests/voice_system_test.py

# Test safety systems
python tests/safety_test.py
```

### Configuration
Edit configuration files to customize behavior:

#### `src/config/settings.py` - Main Configuration
```python
# AI Model Settings
AI_MODEL_LOCAL = "llama-7b"
AI_MODEL_CLOUD = "gpt-4"
VOICE_WAKE_WORD = "hey sarus"

# Safety Thresholds
MAX_TEMPERATURE = 35.0  # Celsius
MAX_HUMIDITY = 80.0     # Percentage
GAS_ALARM_THRESHOLD = 400  # PPM

# Navigation Settings
MAX_SPEED = 0.5  # m/s
OBSTACLE_DISTANCE = 0.3  # meters
```

#### `src/config/hardware_config.py` - Hardware Pin Assignments
```python
# Motor Control Pins
MOTOR_LEFT_PWM = 18
MOTOR_LEFT_DIR1 = 24
MOTOR_LEFT_DIR2 = 25

# Sensor Pins
DHT22_PIN = 4
GAS_SENSOR_PIN = 0  # ADC channel
ULTRASONIC_TRIG = 23
ULTRASONIC_ECHO = 24

# LED Matrix
LED_MATRIX_DIN = 19
LED_MATRIX_CS = 8
LED_MATRIX_CLK = 11
```

### Adding New Features

#### 1. **New Sensor Integration**
```python
# Create sensor class in src/hardware/sensors/
class NewSensor:
    def __init__(self, pin):
        self.pin = pin
    
    def read(self):
        # Sensor reading logic
        return value

# Register in main robot controller
from src.hardware.sensors.new_sensor import NewSensor
robot.add_sensor("new_sensor", NewSensor(pin=22))
```

#### 2. **Custom Voice Commands**
```python
# Add to src/ai/voice_agent.py
def process_custom_command(self, command):
    if "custom action" in command.lower():
        return "Executing custom action"
    return None
```

#### 3. **New Safety Protocols**
```python
# Add to src/safety/safety_manager.py
def check_custom_safety(self):
    if self.custom_sensor.read() > threshold:
        self.trigger_alert("Custom safety alert!")
        return False
    return True
```

### Performance Optimization

#### **Model Quantization**
```bash
# Quantize LLaMA model for faster inference
python scripts/quantize_model.py --model llama-7b --output models/llama-7b-q4
```

#### **Memory Management**
```python
# Configure memory usage in src/config/ai_config.py
MODEL_MAX_MEMORY = "4GB"
CACHE_SIZE = 1000
BATCH_SIZE = 1
```

#### **CPU Optimization**
```bash
# Enable GPU acceleration (if available)
sudo apt install nvidia-cuda-toolkit
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

## ğŸ“š Documentation & Resources

### ğŸ“– **User Guides**
- [Hardware Assembly Guide](docs/hardware_setup.md) - Step-by-step hardware setup
- [Software Installation](docs/software_setup.md) - Complete software setup process  
- [Voice Command Reference](docs/voice_commands.md) - All available voice commands
- [Safety Procedures](docs/safety_guide.md) - Emergency protocols and safety features

### ğŸ”§ **Developer Resources**
- [API Reference](docs/api_reference.md) - Complete API documentation
- [Architecture Overview](docs/architecture.md) - System design and components
- [Contributing Guidelines](CONTRIBUTING.md) - How to contribute to the project
- [Troubleshooting Guide](docs/troubleshooting.md) - Common issues and solutions

### ğŸŒ **Community & Support**
- **GitHub Issues** - Bug reports and feature requests
- **Discussions** - Community support and Q&A
- **Wiki** - Community-maintained documentation
- **Discord Server** - Real-time chat and support

## ğŸ“ License & Legal

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

### Third-Party Licenses
- YOLO models: GPL-3.0 License
- LLaMA models: Custom License (see model documentation)
- OpenCV: Apache 2.0 License
- Raspberry Pi OS: Various open-source licenses

### Privacy & Data Protection
- **Local Processing**: All sensitive data processed on-device
- **No Cloud Storage**: Personal data never leaves the device
- **Encrypted Storage**: User profiles and sensitive data encrypted
- **GDPR Compliant**: Full user control over personal data

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Ways to Contribute
- ğŸ› **Bug Reports** - Report issues and bugs
- âœ¨ **Feature Requests** - Suggest new features
- ğŸ’» **Code Contributions** - Submit pull requests
- ğŸ“š **Documentation** - Improve docs and guides
- ğŸ§ª **Testing** - Help test new features
- ğŸ¨ **Design** - UI/UX improvements for web dashboard

### Development Setup
```bash
# Fork the repository
git clone https://github.com/yourusername/sarus-lab-assistant.git
cd sarus-lab-assistant

# Create development branch
git checkout -b feature/your-feature-name

# Install development dependencies
pip install -r requirements-dev.txt

# Run tests before submitting
python -m pytest tests/
```

---

## ğŸ¯ **Project Vision**

*Sarus represents the future of intelligent lab assistance - where AI, robotics, and safety converge to create a truly autonomous lab companion. By combining the conversational intelligence of Jarvis with the mobility and sensors of Sarus, we're building a robot that doesn't just follow commands, but understands, reasons, and actively contributes to safer, more efficient laboratory environments.*

**Sarus - Making labs smarter, safer, and more interactive, one conversation at a time** ğŸ¤–âœ¨

---

*For the latest updates, documentation, and community discussions, visit our [GitHub repository](https://github.com/mksinha01/sarus-lab-assistant).*
