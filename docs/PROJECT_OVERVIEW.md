# Sarus Robot - Project Documentation

## ğŸ“ Project Structure

```
sarus-robot/
â”œâ”€â”€ src/                          # Main source code
â”‚   â”œâ”€â”€ ai/                       # AI and ML components
â”‚   â”‚   â”œâ”€â”€ speech_manager.py     # Speech recognition & synthesis
â”‚   â”‚   â”œâ”€â”€ llm_manager.py        # Large Language Model interface
â”‚   â”‚   â””â”€â”€ vision_manager.py     # Computer vision & object detection
â”‚   â”œâ”€â”€ core/                     # Core robot functionality
â”‚   â”‚   â””â”€â”€ robot.py              # Main robot controller
â”‚   â”œâ”€â”€ hardware/                 # Hardware control modules
â”‚   â”‚   â”œâ”€â”€ motor_controller.py   # Motor control (L298N)
â”‚   â”‚   â”œâ”€â”€ sensor_manager.py     # Sensor management (ultrasonic, etc.)
â”‚   â”‚   â””â”€â”€ display_controller.py # LED/OLED display control
â”‚   â”œâ”€â”€ navigation/               # Navigation and movement
â”‚   â”‚   â””â”€â”€ navigation_manager.py # Autonomous navigation logic
â”‚   â”œâ”€â”€ communication/            # Communication interfaces
â”‚   â”‚   â””â”€â”€ voice_interface.py    # Voice interaction coordinator
â”‚   â”œâ”€â”€ utils/                    # Utility modules
â”‚   â”‚   â”œâ”€â”€ logger.py             # Logging system
â”‚   â”‚   â”œâ”€â”€ state_manager.py      # State management
â”‚   â”‚   â””â”€â”€ mission_logger.py     # Mission logging
â”‚   â””â”€â”€ config/                   # Configuration files
â”‚       â”œâ”€â”€ settings.py           # Main configuration
â”‚       â””â”€â”€ hardware_config.py    # Hardware-specific settings
â”œâ”€â”€ main.py                       # Application entry point
â”œâ”€â”€ start_sarus.py               # Quick start script
â”œâ”€â”€ test_components.py           # Component testing suite
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ setup.sh                     # Automated setup script
â”œâ”€â”€ README.md                    # Main documentation
â”œâ”€â”€ INSTALLATION.md              # Installation guide
â””â”€â”€ docs/                        # Additional documentation
```

## ğŸ—ï¸ Architecture Overview

### Core Components

1. **SarusRobot** (`src/core/robot.py`)
   - Central robot controller
   - Coordinates all subsystems
   - Manages robot state and lifecycle
   - Handles main operation loop

2. **AI Managers**
   - **SpeechManager**: Speech-to-text, text-to-speech, wake word detection
   - **LLMManager**: Local and cloud LLM integration (Ollama, OpenAI)
   - **VisionManager**: Computer vision, scene analysis, object detection

3. **Hardware Controllers**
   - **MotorController**: L298N motor driver control, movement patterns
   - **SensorManager**: Ultrasonic sensors, environmental monitoring
   - **DisplayController**: LED matrix expressions, status indicators

4. **Navigation System**
   - **NavigationManager**: Autonomous movement, path planning, exploration

5. **Communication**
   - **VoiceInterface**: Coordinates voice-based interactions

### Data Flow

```
Voice Input â†’ SpeechManager â†’ LLMManager â†’ ActionPlanning
                â†“                              â†“
          SarusRobot â† NavigationManager â† Hardware Control
                â†“                              â†“
        VisionManager â†’ Scene Analysis â†’ Object Detection
```

## ğŸ”§ Hardware Integration

### Supported Hardware
- **Raspberry Pi 4** (4GB+ recommended)
- **L298N Motor Driver** for dual DC motors
- **HC-SR04 Ultrasonic Sensors** (front, left, right)
- **LED Matrix Display** for expressions
- **Camera Module** for computer vision
- **USB Audio** for voice interaction
- **Xbox/PS4 Controller** for manual control

### GPIO Pin Configuration
Default GPIO assignments (BCM numbering):
- Motors: Pins 12, 13, 18-21
- Ultrasonic: Pins 1, 7, 8, 23-25
- Display: Pins 9-11
- Status LEDs: Pins 6, 16, 26

## ğŸ¤– AI Integration

### Local AI Models
- **Whisper**: Speech recognition (offline capable)
- **Ollama + LLaMA**: Local language model processing
- **YOLO/OpenCV**: Object detection and scene analysis
- **Porcupine**: Wake word detection

### Cloud AI Fallback
- **OpenAI GPT**: Advanced language processing
- **Cloud STT/TTS**: Backup speech services

## ğŸ® Operation Modes

1. **Interactive Mode**: Voice-controlled operation
2. **Exploration Mode**: Autonomous environment exploration
3. **Manual Mode**: Gamepad-controlled movement
4. **Simulation Mode**: Software testing without hardware
5. **Test Mode**: Component validation and diagnostics

## ğŸ›¡ï¸ Safety Features

- **Emergency Stop**: Immediate halt of all movement
- **Obstacle Detection**: Automatic collision avoidance
- **Battery Monitoring**: Low power warnings and safe shutdown
- **Movement Limits**: Speed and duration constraints
- **Failsafe Modes**: Graceful degradation when components fail

## ğŸ“Š State Management

### Robot States
- `IDLE`: Waiting for commands
- `LISTENING`: Processing voice input
- `THINKING`: AI processing
- `MOVING`: Physical movement
- `EXPLORING`: Autonomous exploration
- `ERROR`: Error recovery mode
- `SHUTDOWN`: Safe shutdown sequence

### Mission Logging
All robot activities are logged including:
- Voice interactions and commands
- Movement patterns and navigation decisions
- Object detection and scene analysis
- Error conditions and recovery actions
- Performance metrics and system status

## ğŸ”„ Development Workflow

### Testing Strategy
1. **Unit Tests**: Individual component validation
2. **Integration Tests**: Multi-component interactions
3. **Simulation Tests**: Full robot behavior without hardware
4. **Hardware Tests**: Real-world validation

### Debugging Tools
- **Component Tester**: `test_components.py`
- **Simulation Mode**: Hardware-free testing
- **Verbose Logging**: Detailed system diagnostics
- **Mission Logs**: Historical activity tracking

## ğŸš€ Deployment

### Development Environment
```bash
python start_sarus.py --mode simulation
```

### Production Deployment
```bash
python start_sarus.py --mode interactive
```

### Service Installation (Optional)
```bash
# Create systemd service for auto-start
sudo cp scripts/sarus.service /etc/systemd/system/
sudo systemctl enable sarus
```

## ğŸ”§ Customization

### Adding New Hardware
1. Update GPIO pin configuration in `hardware_config.py`
2. Create new controller in `src/hardware/`
3. Integrate with main robot controller
4. Add component tests

### Adding New AI Models
1. Implement model interface in appropriate AI manager
2. Add model configuration to settings
3. Update fallback logic
4. Test with simulation mode

### Creating Custom Behaviors
1. Add new methods to `SarusRobot` class
2. Implement in `NavigationManager` or AI managers
3. Add voice commands to `VoiceInterface`
4. Update mission logging

## ğŸ“ˆ Performance Optimization

### Memory Management
- Use appropriate model sizes for hardware
- Implement model caching
- Monitor memory usage during operation

### Processing Optimization
- Async/await for non-blocking operations
- Hardware acceleration where available
- Efficient sensor polling

### Battery Life
- Dynamic performance scaling
- Sleep modes during idle periods
- Low-power sensor configurations

## ğŸ” Security Considerations

### Network Security
- Local-first AI processing
- Encrypted connections for cloud services
- Secure API key management

### Physical Security
- Emergency stop mechanisms
- Movement boundary enforcement
- Safe operating parameters

## ğŸ“š Additional Resources

- **API Documentation**: Auto-generated from docstrings
- **Hardware Guides**: Wiring diagrams and setup instructions
- **Troubleshooting**: Common issues and solutions
- **Community**: Discord server and GitHub discussions

---

**Built with â¤ï¸ for the maker community**
